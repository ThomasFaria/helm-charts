nameOverride: ""
fullnameOverride: "llm-serving"
podAnnotations: {}

deployment:
  image:
    repository: vllm/vllm-openai
    pullPolicy: IfNotPresent
    tag: latest
  hftoken: your_token
  args: 
    model: Llama-3.2-3B-Instruct
    memoryutilization: 0.8
    dtype: half
    maxModelLen: 8208

resources:
  gpu:
    number: 1

service:
  port:
    number: 8000


ingress:
    enabled: false
    className: ""
    annotations: 
      nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
    hostname: "charts.example"

s3:
  enabled: true # Set to true to use S3
  modelHfBucket: ""
  # If not set and create is true, a name is generated using the fullname template
  accessKeyId: "" #$AWS_ACCESS_KEY_ID
  endpoint: "" #$AWS_S3_ENDPOINT
  defaultRegion: "" #$AWS_DEFAULT_REGION
  secretAccessKey: "" #$AWS_SECRET_ACCESS_KEY
  sessionToken: "" #$AWS_SESSION_TOKEN